{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble, preprocessing\n",
    "\n",
    "\n",
    "#setting rootdirectory path \n",
    "rootdir = '/usr/bin/MachineLearning/WestNileVirusPrediction/'\n",
    "\n",
    "# Load Train Dataframe, Test DataFrame and Weather DataFrame \n",
    "\n",
    "train_dataframe = pd.read_csv(rootdir + 'train.csv')\n",
    "test_dataframe = pd.read_csv(rootdir + 'test.csv')\n",
    "weather_dataframe = pd.read_csv(rootdir + 'weather.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_target = train_dataframe.WnvPresent.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping Code Sum, saw this in multiple kaggle scripts submitted. Will see whether to use this later or not\n",
    "weather_dataframe = weather_dataframe.drop('CodeSum', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split station 1 and 2 and join horizontally\n",
    "weather_dataframe_stn1 = weather_dataframe[weather_dataframe['Station']==1]\n",
    "weather_dataframe_stn2 = weather_dataframe[weather_dataframe['Station']==2]\n",
    "weather_dataframe_stn1 = weather_dataframe_stn1.drop('Station', axis=1)\n",
    "weather_dataframe_stn2 = weather_dataframe_stn2.drop('Station', axis=1)\n",
    "weather_dataframe = weather_dataframe_stn1.merge(weather_dataframe_stn2, on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace some missing values and T with -1\n",
    "weather_dataframe = weather_dataframe.replace('M', -1)\n",
    "weather_dataframe = weather_dataframe.replace('-', -1)\n",
    "weather_dataframe = weather_dataframe.replace('T', -1)\n",
    "weather_dataframe = weather_dataframe.replace(' T', -1)\n",
    "weather_dataframe = weather_dataframe.replace('  T', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to extract month and day from dataset. It will be used with Pandas apply to extract Month and day from the Date column\n",
    "def create_month(x):\n",
    "    return x.split('-')[1]\n",
    "\n",
    "def create_day(x):\n",
    "    return x.split('-')[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding new column Month and Day to Train and Test Data Frame\n",
    "train_dataframe['month'] = train_dataframe.Date.apply(create_month)\n",
    "train_dataframe['day'] = train_dataframe.Date.apply(create_day)\n",
    "test_dataframe['month'] = test_dataframe.Date.apply(create_month)\n",
    "test_dataframe['day'] = test_dataframe.Date.apply(create_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Truncating the floating point value latitude/longitude columns and making it integer\n",
    "train_dataframe['Lat_int'] = train_dataframe.Latitude.apply(int)\n",
    "train_dataframe['Long_int'] = train_dataframe.Longitude.apply(int)\n",
    "test_dataframe['Lat_int'] = test_dataframe.Latitude.apply(int)\n",
    "test_dataframe['Long_int'] = test_dataframe.Longitude.apply(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropping columns not needed for train_dataframeing and prediction \n",
    "train_dataframe = train_dataframe.drop(['Address', 'AddressNumberAndStreet','WnvPresent', 'NumMosquitos'], axis = 1)\n",
    "test_dataframe = test_dataframe.drop(['Id', 'Address', 'AddressNumberAndStreet'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join on Date column with weather data\n",
    "train_dataframe = train_dataframe.merge(weather, on='Date')\n",
    "test_dataframe = test_dataframe.merge(weather, on='Date')\n",
    "train_dataframe = train_dataframe.drop(['Date'], axis = 1)\n",
    "test_dataframe = test_dataframe.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert categorical data to numbers\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(train_dataframe['Species'].values) + list(test_dataframe['Species'].values))\n",
    "train_dataframe['Species'] = lbl.transform(train_dataframe['Species'].values)\n",
    "test_dataframe['Species'] = lbl.transform(test_dataframe['Species'].values)\n",
    "\n",
    "lbl.fit(list(train_dataframe['Street'].values) + list(test_dataframe['Street'].values))\n",
    "train_dataframe['Street'] = lbl.transform(train_dataframe['Street'].values)\n",
    "test_dataframe['Street'] = lbl.transform(test_dataframe['Street'].values)\n",
    "\n",
    "lbl.fit(list(train_dataframe['Trap'].values) + list(test_dataframe['Trap'].values))\n",
    "train_dataframe['Trap'] = lbl.transform(train_dataframe['Trap'].values)\n",
    "test_dataframe['Trap'] = lbl.transform(test_dataframe['Trap'].values)\n",
    "\n",
    "# drop columns with -1s\n",
    "train_dataframe = train_dataframe.ix[:,(train_dataframe != -1).any(axis=0)]\n",
    "test_dataframe = test_dataframe.ix[:,(test_dataframe != -1).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_array = train_dataframe.values\n",
    "test_array = test_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest Regressor implementation for prediction\n",
    "#Splitting Training result set into 2 for cross validation\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "tuned_parameters = {'n_estimators': [25, 45, 60], 'max_depth': [None, 1, 2, 3], 'min_samples_split': [1, 2, 3] ,'max_features' : ['auto','sqrt','log2']}\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_array,Y_target, test_size=0.20, random_state=0)\n",
    "\n",
    "clf = GridSearchCV(ensemble.RandomForestClassifier(n_jobs=-1), tuned_parameters, cv=10, scoring='r2')\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
