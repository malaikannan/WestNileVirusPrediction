{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble, preprocessing\n",
    "\n",
    "\n",
    "#setting rootdirectory path \n",
    "rootdir = '/usr/bin/MachineLearning/WestNileVirusPrediction/'\n",
    "\n",
    "# Load Train Dataframe, Test DataFrame and Weather DataFrame \n",
    "\n",
    "train_dataframe = pd.read_csv(rootdir + 'train.csv')\n",
    "test_dataframe = pd.read_csv(rootdir + 'test.csv')\n",
    "weather_dataframe = pd.read_csv(rootdir + 'weather.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_target = train_dataframe.WnvPresent.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping Code Sum, saw this in multiple kaggle scripts submitted. Will see whether to use this later or not\n",
    "weather_dataframe = weather_dataframe.drop('CodeSum', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>Depart</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>WetBulb</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Cool</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Water1</th>\n",
       "      <th>SnowFall</th>\n",
       "      <th>PrecipTotal</th>\n",
       "      <th>StnPressure</th>\n",
       "      <th>SeaLevel</th>\n",
       "      <th>ResultSpeed</th>\n",
       "      <th>ResultDir</th>\n",
       "      <th>AvgSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>83</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1849</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.10</td>\n",
       "      <td>29.82</td>\n",
       "      <td>1.7</td>\n",
       "      <td>27</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>84</td>\n",
       "      <td>52</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.18</td>\n",
       "      <td>29.82</td>\n",
       "      <td>2.7</td>\n",
       "      <td>25</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>-3</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.38</td>\n",
       "      <td>30.09</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.44</td>\n",
       "      <td>30.08</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1851</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.12</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station        Date  Tmax  Tmin Tavg Depart  DewPoint WetBulb Heat Cool  \\\n",
       "0        1  2007-05-01    83    50   67     14        51      56    0    2   \n",
       "1        2  2007-05-01    84    52   68      M        51      57    0    3   \n",
       "2        1  2007-05-02    59    42   51     -3        42      47   14    0   \n",
       "3        2  2007-05-02    60    43   52      M        42      47   13    0   \n",
       "4        1  2007-05-03    66    46   56      2        40      48    9    0   \n",
       "\n",
       "     ...    Sunset Depth Water1 SnowFall PrecipTotal StnPressure SeaLevel  \\\n",
       "0    ...      1849     0      M      0.0        0.00       29.10    29.82   \n",
       "1    ...         -     M      M        M        0.00       29.18    29.82   \n",
       "2    ...      1850     0      M      0.0        0.00       29.38    30.09   \n",
       "3    ...         -     M      M        M        0.00       29.44    30.08   \n",
       "4    ...      1851     0      M      0.0        0.00       29.39    30.12   \n",
       "\n",
       "  ResultSpeed  ResultDir  AvgSpeed  \n",
       "0         1.7         27       9.2  \n",
       "1         2.7         25       9.6  \n",
       "2        13.0          4      13.4  \n",
       "3        13.3          2      13.4  \n",
       "4        11.7          7      11.9  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split station 1 and 2 and join horizontally\n",
    "weather_dataframe_stn1 = weather_dataframe[weather_dataframe['Station']==1]\n",
    "weather_dataframe_stn2 = weather_dataframe[weather_dataframe['Station']==2]\n",
    "weather_dataframe_stn1 = weather_dataframe_stn1.drop('Station', axis=1)\n",
    "weather_dataframe_stn2 = weather_dataframe_stn2.drop('Station', axis=1)\n",
    "weather_dataframe = weather_dataframe_stn1.merge(weather_dataframe_stn2, on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace some missing values and T with -1\n",
    "weather_dataframe = weather_dataframe.replace('M', -1)\n",
    "weather_dataframe = weather_dataframe.replace('-', -1)\n",
    "weather_dataframe = weather_dataframe.replace('T', -1)\n",
    "weather_dataframe = weather_dataframe.replace(' T', -1)\n",
    "weather_dataframe = weather_dataframe.replace('  T', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tmax_x</th>\n",
       "      <th>Tmin_x</th>\n",
       "      <th>Tavg_x</th>\n",
       "      <th>Depart_x</th>\n",
       "      <th>DewPoint_x</th>\n",
       "      <th>WetBulb_x</th>\n",
       "      <th>Heat_x</th>\n",
       "      <th>Cool_x</th>\n",
       "      <th>Sunrise_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunset_y</th>\n",
       "      <th>Depth_y</th>\n",
       "      <th>Water1_y</th>\n",
       "      <th>SnowFall_y</th>\n",
       "      <th>PrecipTotal_y</th>\n",
       "      <th>StnPressure_y</th>\n",
       "      <th>SeaLevel_y</th>\n",
       "      <th>ResultSpeed_y</th>\n",
       "      <th>ResultDir_y</th>\n",
       "      <th>AvgSpeed_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>83</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0448</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.18</td>\n",
       "      <td>29.82</td>\n",
       "      <td>2.7</td>\n",
       "      <td>25</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>-3</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0447</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.44</td>\n",
       "      <td>30.08</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0446</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.46</td>\n",
       "      <td>30.12</td>\n",
       "      <td>12.9</td>\n",
       "      <td>6</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-05-04</td>\n",
       "      <td>66</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0444</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.36</td>\n",
       "      <td>30.04</td>\n",
       "      <td>10.1</td>\n",
       "      <td>7</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-05-05</td>\n",
       "      <td>66</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0443</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>29.46</td>\n",
       "      <td>30.09</td>\n",
       "      <td>11.2</td>\n",
       "      <td>7</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Tmax_x  Tmin_x Tavg_x Depart_x  DewPoint_x WetBulb_x Heat_x  \\\n",
       "0  2007-05-01      83      50     67       14          51        56      0   \n",
       "1  2007-05-02      59      42     51       -3          42        47     14   \n",
       "2  2007-05-03      66      46     56        2          40        48      9   \n",
       "3  2007-05-04      66      49     58        4          41        50      7   \n",
       "4  2007-05-05      66      53     60        5          38        49      5   \n",
       "\n",
       "  Cool_x Sunrise_x    ...     Sunset_y Depth_y  Water1_y SnowFall_y  \\\n",
       "0      2      0448    ...           -1      -1        -1         -1   \n",
       "1      0      0447    ...           -1      -1        -1         -1   \n",
       "2      0      0446    ...           -1      -1        -1         -1   \n",
       "3      0      0444    ...           -1      -1        -1         -1   \n",
       "4      0      0443    ...           -1      -1        -1         -1   \n",
       "\n",
       "  PrecipTotal_y StnPressure_y SeaLevel_y  ResultSpeed_y  ResultDir_y  \\\n",
       "0          0.00         29.18      29.82            2.7           25   \n",
       "1          0.00         29.44      30.08           13.3            2   \n",
       "2          0.00         29.46      30.12           12.9            6   \n",
       "3          0.00         29.36      30.04           10.1            7   \n",
       "4            -1         29.46      30.09           11.2            7   \n",
       "\n",
       "  AvgSpeed_y  \n",
       "0        9.6  \n",
       "1       13.4  \n",
       "2       13.2  \n",
       "3       10.4  \n",
       "4       11.5  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to extract month and day from dataset. It will be used with Pandas apply to extract Month and day from the Date column\n",
    "def create_month(x):\n",
    "    return x.split('-')[1]\n",
    "\n",
    "def create_day(x):\n",
    "    return x.split('-')[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding new column Month and Day to Train and Test Data Frame\n",
    "train_dataframe['month'] = train_dataframe.Date.apply(create_month)\n",
    "train_dataframe['day'] = train_dataframe.Date.apply(create_day)\n",
    "test_dataframe['month'] = test_dataframe.Date.apply(create_month)\n",
    "test_dataframe['day'] = test_dataframe.Date.apply(create_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Truncating the floating point value latitude/longitude columns and making it integer\n",
    "train_dataframe['Lat_int'] = train_dataframe.Latitude.apply(int)\n",
    "train_dataframe['Long_int'] = train_dataframe.Longitude.apply(int)\n",
    "test_dataframe['Lat_int'] = test_dataframe.Latitude.apply(int)\n",
    "test_dataframe['Long_int'] = test_dataframe.Longitude.apply(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['Address' 'AddressNumberAndStreet' 'WnvPresent' 'NumMosquitos'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-351d569453a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# dropping columns not needed for train_dataframeing and prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AddressNumberAndStreet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'WnvPresent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NumMosquitos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Address'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AddressNumberAndStreet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace)\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m   2342\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels %s not contained in axis'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['Address' 'AddressNumberAndStreet' 'WnvPresent' 'NumMosquitos'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# dropping columns not needed for train_dataframeing and prediction \n",
    "train_dataframe = train_dataframe.drop(['Address', 'AddressNumberAndStreet','WnvPresent', 'NumMosquitos'], axis = 1)\n",
    "test_dataframe = test_dataframe.drop(['Id', 'Address', 'AddressNumberAndStreet'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join on Date column with weather data\n",
    "train_dataframe = train_dataframe.merge(weather_dataframe, on='Date')\n",
    "test_dataframe = test_dataframe.merge(weather_dataframe, on='Date')\n",
    "train_dataframe = train_dataframe.drop(['Date'], axis = 1)\n",
    "test_dataframe = test_dataframe.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert categorical data to numbers\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(train_dataframe['Species'].values) + list(test_dataframe['Species'].values))\n",
    "train_dataframe['Species'] = lbl.transform(train_dataframe['Species'].values)\n",
    "test_dataframe['Species'] = lbl.transform(test_dataframe['Species'].values)\n",
    "\n",
    "lbl.fit(list(train_dataframe['Street'].values) + list(test_dataframe['Street'].values))\n",
    "train_dataframe['Street'] = lbl.transform(train_dataframe['Street'].values)\n",
    "test_dataframe['Street'] = lbl.transform(test_dataframe['Street'].values)\n",
    "\n",
    "lbl.fit(list(train_dataframe['Trap'].values) + list(test_dataframe['Trap'].values))\n",
    "train_dataframe['Trap'] = lbl.transform(train_dataframe['Trap'].values)\n",
    "test_dataframe['Trap'] = lbl.transform(test_dataframe['Trap'].values)\n",
    "\n",
    "# drop columns with -1s\n",
    "train_dataframe = train_dataframe.ix[:,(train_dataframe != -1).any(axis=0)]\n",
    "test_dataframe = test_dataframe.ix[:,(test_dataframe != -1).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species              int64\n",
       "Block                int64\n",
       "Street               int64\n",
       "Trap                 int64\n",
       "Latitude           float64\n",
       "Longitude          float64\n",
       "AddressAccuracy      int64\n",
       "month               object\n",
       "day                 object\n",
       "Lat_int              int64\n",
       "Long_int             int64\n",
       "Tmax_x               int64\n",
       "Tmin_x               int64\n",
       "Tavg_x              object\n",
       "Depart_x            object\n",
       "DewPoint_x           int64\n",
       "WetBulb_x           object\n",
       "Heat_x              object\n",
       "Cool_x              object\n",
       "Sunrise_x           object\n",
       "Sunset_x            object\n",
       "Depth_x             object\n",
       "SnowFall_x          object\n",
       "PrecipTotal_x       object\n",
       "StnPressure_x       object\n",
       "SeaLevel_x          object\n",
       "ResultSpeed_x      float64\n",
       "ResultDir_x          int64\n",
       "AvgSpeed_x          object\n",
       "Tmax_y               int64\n",
       "Tmin_y               int64\n",
       "Tavg_y              object\n",
       "DewPoint_y           int64\n",
       "WetBulb_y           object\n",
       "Heat_y              object\n",
       "Cool_y              object\n",
       "PrecipTotal_y       object\n",
       "StnPressure_y       object\n",
       "SeaLevel_y          object\n",
       "ResultSpeed_y      float64\n",
       "ResultDir_y          int64\n",
       "AvgSpeed_y          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for float(): 2100  N CANNON DR, Chicago, IL",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-edfb21c53de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# create predictions and submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WnvPresent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'beat_the_benchmark.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for float(): 2100  N CANNON DR, Chicago, IL"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier \n",
    "clf = ensemble.RandomForestClassifier(n_jobs=-1, n_estimators=1000, min_samples_split=1)\n",
    "clf.fit(train_dataframe, Y_target)\n",
    "\n",
    "# create predictions and submission file\n",
    "predictions = clf.predict_proba(test)[:,1]\n",
    "sample['WnvPresent'] = predictions\n",
    "sample.to_csv(rootdir+'beat_the_benchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_array = train_dataframe.values\n",
    "test_array = test_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [10506 21012]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e34529bf3fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtuned_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_samples_split'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'max_features'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'log2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1808\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1809\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m     cv = ShuffleSplit(n_samples, test_size=test_size,\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 174\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [10506 21012]"
     ]
    }
   ],
   "source": [
    "#Random Forest Regressor implementation for prediction\n",
    "#Splitting Training result set into 2 for cross validation\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "tuned_parameters = {'n_estimators': [25, 45, 60], 'max_depth': [None, 1, 2, 3], 'min_samples_split': [1, 2, 3] ,'max_features' : ['auto','sqrt','log2']}\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_array,Y_target, test_size=0.20, random_state=0)\n",
    "\n",
    "clf = GridSearchCV(ensemble.RandomForestClassifier(n_jobs=-1), tuned_parameters, cv=10, scoring='roc_curve')\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
